{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e2e8ca4",
   "metadata": {
    "tags": [
     "fr"
    ]
   },
   "source": [
    "# Airflow\n",
    "\n",
    "## Qu'est-ce qu'Airflow ?\n",
    "\n",
    "Apache Airflow est une plateforme open-source conçue pour créer, planifier et surveiller des workflows de manière programmatique.\n",
    "\n",
    "Elle est largement utilisée pour orchestrer des pipelines de données complexes et automatiser des tâches en ingénierie des données, en apprentissage automatique et dans d'autres domaines.\n",
    "\n",
    "Airflow permet aux utilisateurs de définir des workflows sous forme de graphes acycliques dirigés (DAG), où chaque tâche représente une étape du pipeline. Ces workflows peuvent être planifiés pour s'exécuter à des intervalles spécifiques et surveillés pour leur statut d'exécution.\n",
    "\n",
    "\n",
    "## Installation\n",
    "\n",
    "De nombreuses façons d'installer Airflow (notamment avec PyPi).\n",
    "\n",
    "https://airflow.apache.org/docs/apache-airflow/stable/installation/index.html\n",
    "\n",
    "Pour le lancer via Docker c'est ici :\n",
    "\n",
    "https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html\n",
    "\n",
    "Notes :\n",
    "\n",
    "- Vous pouvez l'installer avec PyPI\n",
    "- Ensuite, vous pouvez le lancer en mode autonome. Dans ce cas, utilisez cette ligne de commande pour modifier la verbosité :\n",
    "\n",
    "```shell\n",
    "export AIRFLOW__LOGGING__LOGGING_LEVEL=WARNING\n",
    "airflow standalone\n",
    "```\n",
    "\n",
    "## Concepts de base d'Airflow\n",
    "\n",
    "Vidéo de coder2j :\n",
    "\n",
    "https://youtu.be/K9AnJ9_ZAXE?si=FMot2dGl5L26u-cT&t=1078\n",
    "## DAGs et Workflows\n",
    "\n",
    "**Workflow :**  \n",
    "Un workflow est une séquence de tâches ou de processus exécutés pour atteindre un objectif spécifique. Dans le contexte d'Airflow, un workflow est représenté comme un DAG, où chaque nœud est une tâche et les arêtes (appelées aussi \"lignes\") définissent les dépendances. Les workflows automatisent et orchestrent des processus complexes, tels que les pipelines de données, en gérant l'exécution, la planification et la surveillance des tâches.\n",
    "\n",
    "**DAG (Directed Acyclic Graph) :**  \n",
    "Un DAG (en français : Graphe Orienté Acyclique) est un ensemble de toutes les tâches que vous souhaitez exécuter, organisé de manière à montrer clairement leurs relations et dépendances.\n",
    "\n",
    "Dans Airflow, un DAG définit la structure de votre workflow, garantissant que chaque tâche est exécutée dans le bon ordre et seulement lorsque toutes ses dépendances sont satisfaites. La propriété \"acyclique\" signifie qu'il n'y a pas de tâches effectuant des boucles.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"files/airflow_dag_tasks_and_operators.png\" alt=\"Airflow DAG, Tâches et Opérateurs\" style=\"max-width: 75%;\" source=\"https://www.youtube.com/watch?v=K9AnJ9_ZAXE\">\n",
    "</p>\n",
    "\n",
    "**Date d'exécution :**  \n",
    "La date d'exécution est un horodatage logique qui représente le moment où une exécution de DAG est planifiée pour démarrer. Elle est utilisée par Airflow pour suivre et identifier les exécutions d'un workflow (et donc pas nécessairement le moment réel de l'exécution).\n",
    "\n",
    "**Task Instance :**  \n",
    "Une instance de tâche ou *Task Instance* est une exécution spécifique d'une tâche pour une exécution de DAG et une date d'exécution données. Elle représente l'état et le résultat d'une seule exécution d'une tâche au sein d'un workflow. Comme variable, elle est souvent nommée `ti`.\n",
    "\n",
    "**Exécution de DAG (DAG Run) :**  \n",
    "Une exécution de DAG est une instance d'exécution d'un DAG, déclenchée soit par un planning, soit manuellement. Chaque exécution de DAG est associée à une date d'exécution et contient toutes les instances de tâches pour cette exécution particulière.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"files/airflow_dag_run_execution_date_run_task_instance.png\" alt=\"Airflow DAG, Date d'exécution et Instance de tâche\" style=\"max-width: 75%;\">\n",
    "</p>\n",
    "\n",
    "**airflow.cfg :**  \n",
    "`airflow.cfg` est le fichier de configuration principal d'Apache Airflow. Il contient les paramètres qui contrôlent le comportement des composants d'Airflow, tels que le serveur web, le scheduler (planificateur), l'exécuteur et les connexions à la base de données. Vous pouvez modifier ce fichier pour personnaliser votre environnement Airflow.\n",
    "\n",
    "**Serveur Web :**  \n",
    "Le serveur web fournit une interface utilisateur pour Airflow, permettant aux utilisateurs de surveiller les DAGs, de déclencher des exécutions, de consulter les journaux et de gérer les workflows. Il est généralement accessible via un navigateur et est essentiel pour la gestion et le dépannage des workflows.\n",
    "\n",
    "**Scheduler:**  \n",
    "Le scheduler (planificateur) est responsable de la surveillance des définitions de DAG et de la planification des instances de tâches pour exécution en fonction de leurs dépendances et de leurs plannings. Il détermine quand chaque tâche doit s'exécuter et les envoie à l'exécuteur.\n",
    "\n",
    "**Exécuteur (Local ou Séquentiel) :**  \n",
    "L'exécuteur détermine comment et où les tâches sont exécutées.  \n",
    "- **Exécuteur local :** Exécute les tâches dans des processus parallèles (la plupart du temps) sur la même machine, adapté aux charges de travail petites à moyennes.\n",
    "- **Exécuteur séquentiel :** Exécute une tâche à la fois, principalement utilisé pour les tests ou le développement.\n",
    "\n",
    "**Worker :**  \n",
    "Un worker est un processus qui exécute les tâches définies dans vos DAGs. Dans des configurations distribuées (comme avec l'exécuteur Celery), plusieurs workers peuvent exécuter des tâches en parallèle sur différentes machines, augmentant ainsi l'évolutivité et la fiabilité. Chaque worker reçoit des ressources de l'exécuteur pour effectuer ses tâches.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"files/airflow_basic_architecture.png\" alt=\"Architecture de base d'Airflow\" style=\"max-width: 75%;\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc25f4c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
